from datetime import datetime
import json
from pathlib import Path
import re
from typing import Dict, List, Tuple
import uuid


class NotionLoader:
    """
    Notion export íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ JSONìœ¼ë¡œ ë³€í™˜
    """
    
    def __init__(self, input_dir: str, output_path: str):
        """
        Args:
            input_dir: Notion export í´ë” ê²½ë¡œ (data/notion_export/)
            output_path: ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ (data/processed/documents.json)
        """
        self.input_dir = Path(input_dir)
        self.output_path = Path(output_path)
    
    def load_all(self) -> List[Dict]:
        """
        input_dirì˜ ëª¨ë“  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¡œë“œ ë° íŒŒì‹±
        
        Returns:
            íŒŒì‹±ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        documents = []
        
        # .md íŒŒì¼ ì°¾ê¸°
        md_files = list(self.input_dir.glob('**/*.md'))
        
        print(f"ğŸ“‚ ì´ {len(md_files)}ê°œì˜ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë°œê²¬")
        
        for i, file_path in enumerate(md_files, 1):
            try:
                print(f"ğŸ“„ [{i}/{len(md_files)}] íŒŒì‹± ì¤‘: {file_path.name}")
                doc = self.parse_markdown(file_path)
                documents.append(doc)
                print(f"  âœ… ì™„ë£Œ - ì œëª©: {doc['title']}, ë‹¨ì–´: {doc['word_count']}, íƒ€ì…: {doc['content_type']}")
            except Exception as e:
                print(f"  âŒ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"\nâœ¨ ì´ {len(documents)}ê°œ ë¬¸ì„œ íŒŒì‹± ì™„ë£Œ")
        return documents
    
    def parse_markdown(self, file_path: Path) -> Dict:
        """
        ë‹¨ì¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ Document êµ¬ì¡°ë¡œ ë³€í™˜
        
        Args:
            file_path: ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            íŒŒì‹±ëœ ë¬¸ì„œ ë”•ì…”ë„ˆë¦¬
        """
        # 1. íŒŒì¼ ì½ê¸°
        with open(file_path, 'r', encoding='utf-8') as f:
            raw_content = f.read()
        
        # 2. ì œëª© ì¶”ì¶œ (ì›ë³¸ì—ì„œ)
        title = self.extract_title(raw_content)

        # 2-1. ì œëª© ì¤„ ì œê±°
        content = self.remove_title_line(raw_content)

        # 3. ì°¸ì¡° ì„¹ì…˜ ì œê±°
        content = self.remove_references_section(content)
        
        # 4. ì´ë¯¸ì§€ ì œê±°
        content = self.remove_images(content)
        
        # 5. í…Œì´ë¸” ë³€í™˜
        content = self.parse_table(content)
        
        # 6. ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        content, code_blocks = self.extract_code_blocks(content)
        
        # 7. content_type íŒë‹¨
        content_type = self.determine_content_type(content, code_blocks)
        
        # 8. ëŒ€í‘œ ì–¸ì–´ ì¶”ì¶œ
        language = self.get_dominant_language(code_blocks)
        
        # 9. ë‹¨ì–´ ìˆ˜ ê³„ì‚°
        word_count = len(content.split())
        
        # 10. ë©”íƒ€ë°ì´í„° ìƒì„±
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        return {
            "page_id": str(uuid.uuid4()),
            "title": title,
            "content": content.strip(),
            "content_type": content_type,
            "language": language,
            "file_path": str(file_path),
            "word_count": word_count,
            "status": "active",
            "created_at": now,
            "updated_at": now,
            "tags": [],
            "url": "",
            "code_blocks": code_blocks
        }

    def extract_title(self, content: str) -> str:
        """
        ë§ˆí¬ë‹¤ìš´ì—ì„œ ì²« ë²ˆì§¸ # ì œëª© ì¶”ì¶œ (ì²« ë²ˆì§¸ \nê¹Œì§€ë§Œ)
        
        Args:
            content: ë§ˆí¬ë‹¤ìš´ ë³¸ë¬¸
            
        Returns:
            ì œëª© (ì—†ìœ¼ë©´ "Untitled")
        """
        # [^\n]+ ëŠ” \nì´ ì•„ë‹Œ ë¬¸ìë“¤ì„ ë§¤ì¹­ (ì²« ë²ˆì§¸ ì¤„ë°”ê¿ˆ ì „ê¹Œì§€)
        pattern = r'^# ([^\n]+)'
        match = re.search(pattern, content, re.MULTILINE)
        
        if match:
            return match.group(1).strip()
        else:
            return "Untitled"
        
    def remove_title_line(self, content: str) -> str:
        """
        ì²« ë²ˆì§¸ # ì œëª© ì¤„ ì œê±°
        
        Args:
            content: ë§ˆí¬ë‹¤ìš´ ë³¸ë¬¸
            
        Returns:
            ì œëª©ì´ ì œê±°ëœ ë³¸ë¬¸
        """
        # ì²« ë²ˆì§¸ # ì œëª© ì¤„ì„ ì°¾ì•„ì„œ ì œê±°
        pattern = r'^# [^\n]+\n+'
        content = re.sub(pattern, '', content, count=1, flags=re.MULTILINE)
        
        return content
    
    def extract_code_blocks(self, content: str) -> Tuple[str, List[Dict]]:
        """
        ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ ë° í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ì¹˜í™˜
        
        Args:
            content: ë§ˆí¬ë‹¤ìš´ ë³¸ë¬¸
            
        Returns:
            (ì¹˜í™˜ëœ ë³¸ë¬¸, ì½”ë“œ ë¸”ë¡ ë¦¬ìŠ¤íŠ¸)
        """
        code_blocks = []

        # ì •ê·œì‹: ```language\n...``` íŒ¨í„´
        pattern = r'```(\w*)\n(.*?)```'

        def replace_with_placeholder(match):
            language = match.group(1) or 'plaintext'  # ì–¸ì–´ ì •ë³´ ì—†ìœ¼ë©´ plaintext
            code = match.group(2).strip()
            
            block_id = f"CODE_BLOCK_{len(code_blocks)}"
            code_blocks.append({
                "id": block_id,
                "language": language,
                "code": code
            })
            
            return f"[{block_id}]"    
        
        # ì½”ë“œ ë¸”ë¡ì„ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ì¹˜í™˜
        modified_content = re.sub(pattern, replace_with_placeholder, content, flags=re.DOTALL)
        
        return modified_content, code_blocks

    def parse_table(self, content: str) -> str:
        """
        ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì„ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            content: ë§ˆí¬ë‹¤ìš´ ë³¸ë¬¸
            
        Returns:
            í…Œì´ë¸”ì´ ë³€í™˜ëœ ë³¸ë¬¸
        """
        # í…Œì´ë¸” íŒ¨í„´: | header1 | header2 | ... |
        #             |---------|---------|-----|
        #             | value1  | value2  | ... |
        
        # í…Œì´ë¸” ì „ì²´ë¥¼ ì°¾ëŠ” ì •ê·œì‹
        table_pattern = r'\|(.+)\|\n\|[-:\s\|]+\|\n((?:\|.+\|\n?)+)'
        
        def replace_table(match):
            header_line = match.group(1)
            rows_text = match.group(2)
            
            # í—¤ë” íŒŒì‹±
            headers = [h.strip() for h in header_line.split('|') if h.strip()]
            
            # ê° í–‰ íŒŒì‹±
            rows = []
            for row_line in rows_text.strip().split('\n'):
                if not row_line.strip():
                    continue
                values = [v.strip() for v in row_line.split('|') if v.strip()]
                
                # í—¤ë” ê°œìˆ˜ì™€ ê°’ ê°œìˆ˜ê°€ ë§ì§€ ì•Šìœ¼ë©´ ìŠ¤í‚µ
                if len(values) != len(headers):
                    continue
                
                # "í—¤ë”: ê°’" í˜•íƒœë¡œ ë³€í™˜
                row_text = ', '.join([f"{h}: {v}" for h, v in zip(headers, values)])
                rows.append(row_text)
            
            # ê° í–‰ì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°
            return '\n'.join(rows)
        
        # í…Œì´ë¸”ì„ ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¡œ ì¹˜í™˜
        modified_content = re.sub(table_pattern, replace_table, content)
        
        return modified_content
    
    def remove_references_section(self, content: str) -> str:
        """
        ì°¸ì¡° ì„¹ì…˜ ì œê±°
        
        ## ì°¸ì¡° ë˜ëŠ” ### ì°¸ì¡° ì´í›„ ëª¨ë“  ë‚´ìš© ì œê±°
        
        Args:
            content: ë§ˆí¬ë‹¤ìš´ ë³¸ë¬¸
            
        Returns:
            ì°¸ì¡° ì„¹ì…˜ì´ ì œê±°ëœ ë³¸ë¬¸
        """
        # ### ì°¸ì¡° ë˜ëŠ” ## ì°¸ì¡° íŒ¨í„´
        patterns = [
            r'^###\s*ì°¸ì¡°.*$.*',  # ### ì°¸ì¡°
            r'^##\s*ì°¸ì¡°.*$.*',   # ## ì°¸ì¡°
            r'^###\s*Reference.*$.*',  # ì˜ì–´ ë²„ì „
            r'^##\s*Reference.*$.*'
        ]
        
        for pattern in patterns:
            content = re.sub(pattern, '', content, flags=re.MULTILINE | re.DOTALL)
        
        return content


    def remove_images(self, content: str) -> str:
        """
        ì´ë¯¸ì§€ ë§ˆí¬ë‹¤ìš´ ì œê±°
        
        ![alt text](path) â†’ (ì œê±°)
        
        Args:
            content: ë§ˆí¬ë‹¤ìš´ ë³¸ë¬¸
            
        Returns:
            ì´ë¯¸ì§€ê°€ ì œê±°ëœ ë³¸ë¬¸
        """
        # ì´ë¯¸ì§€ íŒ¨í„´: ![...](...)
        pattern = r'!\[([^\]]*)\]\([^\)]+\)'
        content = re.sub(pattern, '', content)
        
        return content

    def determine_content_type(self, content: str, code_blocks: List) -> str:
        """
        content_type ìë™ íŒë‹¨ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        """
        if len(code_blocks) == 0:
            return 'text'
        
        word_count = len(content.split())
        
        # ì„¤ëª…ì´ ê±°ì˜ ì—†ìœ¼ë©´ code (ì„ê³„ê°’: 20ë‹¨ì–´)
        if word_count < 20:
            return 'code'
        
        # ì½”ë“œ + ì„¤ëª…ì´ ë‘˜ ë‹¤ ìˆìœ¼ë©´ mixed
        return 'mixed'

    def get_dominant_language(self, code_blocks: List) -> str:
        if not code_blocks:
            return None
        
        # ì–¸ì–´ë³„ ë“±ì¥ íšŸìˆ˜ ì¹´ìš´íŠ¸ (plaintext ì œì™¸)
        language_count = {}
        for block in code_blocks:
            lang = block.get('language', 'plaintext')
            if lang != 'plaintext': # plaintextëŠ” ì œì™¸
                language_count[lang] = language_count.get(lang, 0) + 1
        
        # ì‹¤ì œ ì–¸ì–´ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ None
        if not language_count:
            return None
        
        # ê°€ì¥ ë§ì´ ë“±ì¥í•œ ì–¸ì–´ ë°˜í™˜
        dominant_lang = max(language_count, key=language_count.get)
        
        return dominant_lang

    def save_to_json(self, documents: List[Dict]):
        """
        íŒŒì‹±ëœ ë¬¸ì„œë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            documents: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # JSON ì €ì¥
        with open(self.output_path, 'w', encoding='utf-8') as f:
            json.dump(documents, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {self.output_path}")
        print(f"   - ì´ ë¬¸ì„œ ìˆ˜: {len(documents)}")
        print(f"   - íŒŒì¼ í¬ê¸°: {self.output_path.stat().st_size / 1024:.2f} KB")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ê²½ë¡œ ì„¤ì •
    input_dir = "../data/notion_export"
    output_path = "../data/processed/documents.json"
    
    # NotionLoader ì´ˆê¸°í™”
    loader = NotionLoader(input_dir, output_path)
    
    # ëª¨ë“  íŒŒì¼ ë¡œë“œ
    documents = loader.load_all()
    
    # JSONìœ¼ë¡œ ì €ì¥
    loader.save_to_json(documents)
    
    # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
    print("\nğŸ“Š íŒŒì‹± í†µê³„:")
    content_types = {}
    languages = {}
    
    for doc in documents:
        ct = doc['content_type']
        content_types[ct] = content_types.get(ct, 0) + 1
        
        if doc['language']:
            lang = doc['language']
            languages[lang] = languages.get(lang, 0) + 1
    
    print(f"   Content Types: {content_types}")
    print(f"   Languages: {languages}")


if __name__ == "__main__":
    main()